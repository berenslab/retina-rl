help: false
algo: APPO
env: gathering_cifar
experiment: gathering_cifar_1
train_dir: train_dir/complexity-complex-elu
restart_behavior: resume
device: gpu
seed: null
num_policies: 1
async_rl: true
serial_mode: false
batched_sampling: false
num_batches_to_accumulate: 2
worker_num_splits: 2
policy_workers_per_policy: 1
max_policy_lag: 1000
num_workers: 24
num_envs_per_worker: 8
batch_size: 2048
num_batches_per_epoch: 1
num_epochs: 1
rollout: 32
recurrence: 32
shuffle_minibatches: false
gamma: 0.99
reward_scale: 0.1
reward_clip: 1000.0
value_bootstrap: false
normalize_returns: false
exploration_loss_coeff: 0.001
value_loss_coeff: 0.5
kl_loss_coeff: 0.0
exploration_loss: symmetric_kl
gae_lambda: 0.95
ppo_clip_ratio: 0.1
ppo_clip_value: 0.2
with_vtrace: true
vtrace_rho: 1.0
vtrace_c: 1.0
optimizer: adam
adam_eps: 1e-06
adam_beta1: 0.9
adam_beta2: 0.999
max_grad_norm: 4.0
learning_rate: 0.0001
lr_schedule: constant
lr_schedule_kl_threshold: 0.008
obs_subtract_mean: 0.0
obs_scale: 255.0
normalize_input: true
normalize_input_keys: null
decorrelate_experience_max_seconds: 0
decorrelate_envs_on_one_worker: true
actor_worker_gpus: []
set_workers_cpu_affinity: true
force_envs_single_thread: false
default_niceness: 0
log_to_file: true
experiment_summaries_interval: 10
flush_summaries_interval: 30
stats_avg: 100
summaries_use_frameskip: true
heartbeat_interval: 20
heartbeat_reporting_interval: 180
train_for_env_steps: 10000000000
train_for_seconds: 10000000000
save_every_sec: 120
keep_checkpoints: 2
load_checkpoint_kind: latest
save_milestones_sec: -1
save_best_every_sec: 5
save_best_metric: reward
save_best_after: 100000
benchmark: false
encoder_mlp_layers:
  - 512
  - 512
encoder_conv_architecture: convnet_simple
encoder_conv_mlp_layers:
  - 512
use_rnn: false
rnn_size: 64
rnn_type: gru
rnn_num_layers: 1
decoder_mlp_layers: []
nonlinearity: elu
policy_initialization: orthogonal
policy_init_gain: 1.0
actor_critic_share_weights: true
adaptive_stddev: true
continuous_tanh_scale: 0.0
initial_stddev: 1.0
use_env_info_cache: false
env_gpu_actions: false
env_gpu_observations: true
env_frameskip: 4
env_framestack: 1
pixel_format: CHW
use_record_episode_statistics: false
with_wandb: true
wandb_user: null
wandb_project: retinal-rl
wandb_group: complexity
wandb_job_type: complex
wandb_tags: []
with_pbt: false
pbt_mix_policies_in_one_env: true
pbt_period_env_steps: 5000000
pbt_start_mutation: 20000000
pbt_replace_fraction: 0.3
pbt_mutation_rate: 0.15
pbt_replace_reward_gap: 0.1
pbt_replace_reward_gap_absolute: 1e-06
pbt_optimize_gamma: false
pbt_target_objective: true_objective
pbt_perturb_min: 1.1
pbt_perturb_max: 1.5
num_agents: -1
num_humans: 0
num_bots: -1
start_bot_difficulty: null
timelimit: null
res_w: 120
res_h: 90
wide_aspect_ratio: false
global_channels: 16
retinal_bottleneck: 4
vvs_depth: 1
kernel_size: 7
retinal_stride: 2
activation: elu
greyscale: false
repeat: 1
eval_env_frameskip: 1
fps: 35
max_num_frames: 10000
max_num_episodes: 100
command_line: "--activation=elu --env=gathering_cifar --experiment={env}_{repeat} --global_channels=16 --kernel_size=7 --normalize_returns=False --num_envs_per_worker=8 --num_workers=24 --recurrence=32 --repeat=1 --res_h=90 --res_w=120 --retinal_bottleneck=4 --retinal_stride=2 --rnn_size=64 --rollout=32 --train_dir=train_dir/{wandb_group}-{wandb_job_type}-elu --train_for_env_steps=10000000000 --use_rnn=False --vvs_depth=1 --wandb_group=complexity --wandb_job_type=complex --wide_aspect_ratio=False --with_vtrace=True"
cli_args:
  env: gathering_cifar
  experiment: "{env}_{repeat}"
  train_dir: "train_dir/{wandb_group}-{wandb_job_type}-elu"
  num_workers: 24
  num_envs_per_worker: 8
  rollout: 32
  recurrence: 32
  normalize_returns: false
  with_vtrace: true
  train_for_env_steps: 10000000000
  use_rnn: false
  rnn_size: 64
  wandb_group: complexity
  wandb_job_type: complex
  res_w: 120
  res_h: 90
  wide_aspect_ratio: false
  global_channels: 16
  retinal_bottleneck: 4
  vvs_depth: 1
  kernel_size: 7
  retinal_stride: 2
  activation: elu
  repeat: 1
git_hash: db8a0f39cc761553e0c2e1f59771346e11313cf8
git_repo_name: https://github.com/berenslab/retinal-rl
train_script: train
wandb_unique_id: gathering_cifar_1_20230304_005951_901407
